<!DOCTYPE HTML>

<style>
  .regular-text {
    font-size: 16px;
    font-family: Verdana, Geneva, sans-serif;
  }
</style>

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shaun Mendes</title>

  <meta name="author" content="Shaun Mendes">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22https://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Shaun Mendes</name>
                  </p>
                  <p align="justify" ; font-size: 50px>
                    Hey ! I am a Masters student studying Machine Learning at the <a href="https://www.stevens.edu/"
                      target="_blank">Stevens Institute Of Technology</a>.
                    I work at the intersection of Robotics, Computer Vision and Machine learning.
                    <br>
                    <br>
                    Prior to joining UCSD, I had been working as Machine Learning Scientist at <a
                      href="https://www.tomtom.com/"> TomTom </a> and
                    <a href="https://fractal.ai/"> Fractal.ai </a>, where I worked on building and deploying machine
                    learning and computer vision models.
                    <br>
                    <br>
                    I have also had the fortune of working in robotics and computer vision research
                    with<a href="https://www.iiit.ac.in/people/faculty/mkrishna/" target="_blank"> Prof. Madhava Krishna
                    </a> at IIIT Hyderabad and <a href="https://yip.eng.ucsd.edu/" target="_blank"> Prof. Michael Yip
                    </a> at UC San Diego
                  </p>
                  <p align="justify">
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:sjindal@ucsd.edu">Email</a> &nbsp/&nbsp
                    <a href="data/SakshamJindal-Resume.pdf" target="_blank">Resume</a> &nbsp/&nbsp
                    <a href="https://linkedin.com/in/sakshamjindal" target="_blank">Linkedin</a> &nbsp/&nbsp
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                    <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                    <a href="https://twitter.com/SAKSHAM111" target="_blank">Twitter</a> &nbsp/&nbsp
                    <a href="https://github.com/sakshamjindal/" target="_blank">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/SakshamJindal.jpeg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/SakshamJindal.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Experience - Heading -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Professional Experience</heading>
                  <!-- <p>
                  I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
                </p> -->
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Experience - Content -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <table border=0 class="bg_colour"
                style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                      <div class="one">
                        <img src='images/tomtom.png' width="120">
                      </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                      <papertitle style="color:rgb(110, 110, 110)"><big>Senior Data Scientist</big> </papertitle>
                      <papertitle><big> | TomTom, Inc.</big></papertitle>
                      <br>
                      November 2021 - August 2022
                      <br>
                      <p align="justify">
                        Worked with <a
                          href="https://www.tomtom.com/newsroom/behind-the-map/the-future-of-mapmaking-tomtom-maps-platform/"
                          target="_blank"> Map Making Platform </a>
                        team at TomTom, Inc. on building computer vision and machine learning models for aerial
                        perception, automated integration and generation of road geometry using satellite image data for
                        ingestion into
                        real-time navigation unit of TomTom‚Äôs ADAS <a
                          href="https://www.tomtom.com/products/navigation-map/" target="_blank"> navigation maps </a>.
                        <br>
                      </p>
                      <i> Tools and Technologies </i>: pytorch, pytorch lightning, Azure ML, Azure Databricks, XGboost,
                      LightGBM, scikit-learn, pandas, numpy
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                      <div class="one">
                        <img src='images/fractal.png' width="120">
                      </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                      <papertitle style="color:rgb(110, 110, 110)"><big> Machine Learning Scientist </big> </papertitle>
                      <papertitle><big> | Fractal, Inc.</big></papertitle>
                      <br>
                      June 2018 - October 2021
                      <br>
                      <p align="justify">Worked with the <a href="https://fractal.ai/image-video-analytics"
                          target="_blank"> Image and Video Analytics </a> team at Fractal
                        on product offering of platform for image and video understanding using deep learning and
                        computer vision. Also, worked with Fortune 500
                        clients such as <a href="https://www.sky.com/" target="_blank"> Sky UK </a>, <a
                          href="https://www.mars.com/" target="_blank"> Mars </a> and
                        <a href="https://us.pg.com/" target="_blank"> Procter & Gamble </a> on projects involving
                        forecasting, time series analysis and predictive analytics using machine learning.
                      </p>
                      <i> Tools and Technologies </i>: python, pytorch, tensorflow, pytorch lightning, OpenCV, docker,
                      git,
                      Fast API, django, Google Cloud Platform (GCP), Airflow, Jenkins, Numpy, Pandas, Scipy,
                      Scikit-learn, Statsmodel, Matplotlib, Jupyter
                      <br>
                      <br>
                    </td>
                  </tr>
                </tbody>
              </table>
              </div>
              <!-- <hr class="soft"> -->

              <!-- Research - Heading -->
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <heading>Research Experience</heading>
                      <!-- <p>
                  I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
                </p> -->
                    </td>
                  </tr>
                </tbody>
              </table>

              <!-- Research - Content -->
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <table border=0 class="bg_colour"
                    style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/ucsd2.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:rgb(110, 110, 110)"><big>Research Asssistant</big> </papertitle>
                          <papertitle><big> | Advanced Robotics and Controls Lab, UC San Diego </big></papertitle>
                          <br>
                          January 2023 - Present
                          <br>
                          <p align="justify">
                            Currently working with <a href="https://yip.eng.ucsd.edu/" target="_blank"> Prof. Michael
                              Yip </a> on robotics manipulation of deformable objects
                            using 3D vision-based forward and invese dynamics for goal conditioned manipulation with
                            appliction in surgical robotics. Also, worked
                            on building SE(3) equivariant and deformation invariant neural representations for tasks
                            such as grasping, manipulating, or
                            interacting with deformable objects
                            <br>
                          </p>
                          <i> Tools and Technologies </i>: python, pytorch, pytorch lightning, OpenCV
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/iiith.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:rgb(110, 110, 110)"><big>Research Intern</big> </papertitle>
                          <papertitle><big> | Robotics Research Centre, IIIT Hyderabad </big></papertitle>
                          <br>
                          April 2021 - December 2021
                          <br>
                          <p align="justify">
                            Worked with <a href="https://www.iiit.ac.in/people/faculty/mkrishna/" target="_blank"> Prof.
                              Madhava Krishna </a> developing pipeline for online incremental localization and mapping
                            (SLAM) for indoor 3D scenes using implicit
                            representation formulated by neural radiance fields (NeRF) and finding relative pose between
                            NeRF submaps
                            <br>
                          </p>
                          <i> Tools and Technologies </i>: python, pytorch, pytorch lightning, OpenCV, Open3d,
                          transforms3d, pybullet
                        </td>
                      </tr>
                    </tbody>
                  </table>
                  </div>
                  <!-- <hr class="soft"> -->

                  <!-- Open Source - Heading -->
                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                          <heading>Open Source Projects</heading>
                          <!-- <p>
                  I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
                </p> -->
                        </td>
                      </tr>
                    </tbody>
                  </table>

                  <!-- Open Source - Contents -->
                  <table border=0 class="bg_colour"
                    style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>

                      <!-- Diffusion Project -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/diffusion_arch.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black">Controllable subject guided
                            text-to-image generation and editing using diffusion models
                          </papertitle>
                          <br>
                          <a href='data/Diffusion_Dreambooth.pdf'> Paper</a> /
                          <a href='https://github.com/sakshamjindal/Subject2Subject'> Code </a>
                          <br>
                          <br>
                          Developed pipeline for personalized text-to-image generation and editing using latent
                          diffusion models
                          (generative AI), incorporating LoRA finetuning for image generation and cross-attention
                          guidance for image editing
                          <i>(pytorch / hugging face diffusers /stable diffusion) </i>
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, pytorch, hugging face diffusers, stable diffusion,
                          OpenCV, transformers
                          <br>
                          <!-- # make italic -->

                        </td>
                      </tr>
                      <!-- Visual Odometry Project -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/vo-slam.gif' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black">Stereo visual SLAM with local bundle adjustment on KITTI
                            dataset </papertitle>
                          <br>
                          <a href='https://github.com/sakshamjindal/Stereo-Visual-SLAM-Odometry'> Code </a> /
                          <a href='https://youtu.be/GnvAO-jpMPo'> Demo Video </a>
                          <br>
                          <br>
                          Implemented a Visual SLAM pipeline for 6-DOF camera pose estimation and outdoor scene mapping
                          using techniques
                          in multi-view geometry - RANSAC, feature tracking, 3D reconstruction, pose estimation (PnP
                          algorithm) and
                          bundle adjustment
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, pytorch, hugging face diffusers, stable diffusion,
                          OpenCV, transformers
                        </td>
                      </tr>

                      <!-- Satellite Image Segmentation -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/satellite.png' width="100" height="100">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black"> How to Extract Roads from Satellite Images using Semantic
                            Segmentation? </papertitle>
                          <br>
                          <a href='data/Road_Extraction_from_Satellite_Images.pdf'> Paper</a> /
                          <a href='https://github.com/sakshamjindal/Satellite-Road-Segmentation'> Code </a>
                          <br>
                          <br>
                          Developed framework for extraction of road geometry from satellite images using convolutional
                          neural network (CNN)
                          based semantic segmentation architectures experimenting with data augmentations, schedulers,
                          optimizers and loss functions
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, pytorch, pytorch-segmentation, torchvision, pillow
                        </td>
                      </tr>

                      <!-- Particle Filter SLAM -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/pf-slam.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black">Particle Filter SLAM for an indoor differential-drive robot
                          </papertitle>
                          <br>
                          <a href='data/PF-SLAM.pdf'> Paper</a> /
                          <a href='https://github.com/sakshamjindal/particle-filter-slam'> Code </a>
                          <br>
                          <br>
                          Created Particle Filter SLAM pipeline using IMU odometry data and LiDAR scans from sensors
                          mounted on the
                          differential drive robot to enable localization and build occupancy grid map of the
                          environment
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, numpy, matplotlib, OpenCV
                        </td>
                      </tr>

                      <!-- Particle Filter SLAM -->
                      <!-- <tr>
              <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                  <div class="one">
                      <img src='images/diffusion_arch.png' width="120">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <papertitle style="color:black">LEAD: Self-Supervised Landmark Estimation 
                    by Aligning Distributions of Feature Similarity </papertitle>
                  <br>
                  <a href = 'https://openaccess.thecvf.com/content/WACV2022/papers/Karmali_LEAD_Self-Supervised_Landmark_Estimation_by_Aligning_Distributions_of_Feature_Similarity_WACV_2022_paper.pdf'> Paper</a> /
                  <a href = 'https://openaccess.thecvf.com/content/WACV2022/supplemental/Karmali_LEAD_Self-Supervised_Landmark_WACV_2022_supplemental.pdf'> Code </a>             
                  <br>
                  <p align="justify">Tejan Karmali*, Abhinav Atrishi*, <b>Sai Sree Harsha</b>, Susmit Agrawal, Varun Jampani, Venkatesh Babu</p>
                  <br>
              </td>
            </tr> -->

                      <!-- Variational Autoencoder -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/medvae.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black"> MedVAE: Generating Chest X-Ray Images using
                            Variational Autoencoders (VAE) </papertitle>
                          <br>
                          <a href='data/MedVAE.pdf'> Paper</a> /
                          <a
                            href='https://colab.research.google.com/drive/1eRYx3okk8KX7tqIvareTujeXTkD2S-hZ?usp=sharing'>
                            Code </a>
                          <br>
                          <br>
                          Programmed variational auto-encoder (VAE) trained on a dataset of chest X-rays from patients
                          diagnosed with pneumonia
                          to generate realistic and representative chest X-ray images for improved diagnostic
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, pytorch, numpy, matplotlib, OpenCV, matplotlib
                        </td>
                      </tr>

                      <!-- Generative Adversial Network -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/art-gan.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black"> GAN-Art: Generating Artwork using Deep
                            Convolutional Generative Adversarial Networks (DCGANs) </papertitle>
                          <br>
                          <a href='data/GAN-Art.pdf'> Paper</a> /
                          <a
                            href='https://colab.research.google.com/drive/13Ms2db3aRiJRRn0BFTvd7YYfpMdJPeb9?usp=sharing'>
                            Code </a>
                          <br>
                          <br>
                          Programmed deep convolutional generative adversarial network (DCGAN) trained on 50,000+ images
                          from 10 different artistic styles
                          to generate high-quality and realistic artwork images that closely resemble the
                          characteristics of each artistic style
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, pytorch, numpy, matplotlib, OpenCV, matplotlib
                        </td>
                      </tr>

                      <!-- Orientation Tracking -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/orientation-slam.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black">
                            Optimised orientation tracking using Riemann stochastic gradient descent
                          </papertitle>
                          <br>
                          <a href='data/optimised_orientation_tracking.pdf'> Paper</a> /
                          <a href='https://github.com/sakshamjindal/optimised-orientation-tracking'> Code </a>
                          <br>
                          <br>
                          Worked on orientation tracking of a rotating body using quartenion kinematics on IMU data,
                          constrained optimization
                          using Riemannian stochastic gradient descent and generating 360-degree spherical panorama of
                          the indoor scene
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, jax, numpy, matplotlib, OpenCV, matplotlib
                        </td>
                      </tr>

                      <!-- Contrastive Learning -->
                      <tr>
                        <td style="padding:10px;width:25%;vertical-align:middle;padding-top: 20px;">
                          <div class="one">
                            <img src='images/contrastive2.png' width="120">
                          </div>
                        </td>
                        <td style="padding:10px;width:75%;vertical-align:top">
                          <papertitle style="color:black">
                            Object-centric visual and spatial representations on multi-view CLEVR dataset
                          </papertitle>
                          <br>
                          <a
                            href='https://docs.google.com/document/d/1cFwUBQ8Ix5qyjrnMymZZuqNy7Nlx4gaMoQ2XeGmeE1M/edit?usp=sharing'>
                            Doc</a> /
                          <a href='https://github.com/sakshamjindal/Non-Metric-3d-Representation'> Code </a>
                          <br>
                          <br>
                          Researched on momentum contrastive learning to build view invariant visual and view-dependent
                          spatial object centric embeddings to build scene graph on multi-view CLEVR dataset
                          <br>
                          <br>
                          <i> Tools and Technologies </i>: python, pytorch, numpy, matplotlib, OpenCV
                        </td>
                      </tr>



                    </tbody>
                  </table>

                  <!-- Footer - Template Credits -->

                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:0px">
                          <br>
                          <p style="text-align:center;font-size:small;">
                            <a href="https://jonbarron.info/" target="_blank">Template credits</a>
                          </p>
                        </td>
                      </tr>
                    </tbody>
                  </table>

        </td>
      </tr>
  </table>



</body>

</html>